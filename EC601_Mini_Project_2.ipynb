{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EC601_Mini_Project_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "YIdfml-gSagZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "!rm *.jpg\n",
        "!rm *.txt\n",
        "!rm *.JPG\n",
        "\n",
        "\n",
        "#Upload images to google colab\n",
        "print(\"Upload Training Images...\")\n",
        "train_images = files.upload()\n",
        "print(\"Upload Training Labels...\")\n",
        "train_labels = files.upload()\n",
        "print(\"Upload Validation Images...\")\n",
        "validation_images = files.upload()\n",
        "print(\"Upload Validation Labels...\")\n",
        "validation_labels = files.upload()\n",
        "print(\"Upload Testing Images...\")\n",
        "test_images = files.upload()\n",
        "print(\"Upload Testing Labels...\")\n",
        "test_labels = files.upload()\n",
        "\n",
        "\n",
        "##Preprocessing of Images\n",
        "\n",
        "#create lists of files for training, validation, and test images\n",
        "train_images_list = list(train_images.keys())\n",
        "validation_images_list = list(validation_images.keys())\n",
        "test_images_list = list(test_images.keys())\n",
        "\n",
        "#create lists of files for training, validation, and test labels\n",
        "train_labels_list = list(train_labels.keys())\n",
        "validation_labels_list = list(validation_labels.keys())\n",
        "test_labels_list = list(test_labels.keys())\n",
        "\n",
        "#get pixel array of training dataset\n",
        "train_images_array = []\n",
        "for image in train_images_list:\n",
        "  image_pixel_array = cv2.imread(image)\n",
        "  train_images_array.append(image_pixel_array)\n",
        "#convert array to numpy array\n",
        "train_images_nparray = np.array(train_images_array)\n",
        "\n",
        "#get pixel array of validation dataset\n",
        "validation_images_array = []\n",
        "for image in validation_images_list:\n",
        "  image_pixel_array = cv2.imread(image)\n",
        "  validation_images_array.append(image_pixel_array)\n",
        "#convert array to numpy array\n",
        "validation_images_nparray = np.array(validation_images_array)\n",
        "\n",
        "#get pixel array of test dataset\n",
        "test_images_array = []\n",
        "for image in test_images_list:\n",
        "  image_pixel_array = cv2.imread(image)\n",
        "  test_images_array.append(image_pixel_array)\n",
        "#convert array to numpy array\n",
        "test_images_nparray = np.array(test_images_array)\n",
        "\n",
        "#make all pixel values between 0 and 1\n",
        "train_images_nparray = train_images_nparray / 255.0\n",
        "validation_images_nparray = validation_images_nparray / 255.0\n",
        "test_images_nparray = test_images_nparray / 255.0\n",
        "\n",
        "#Save all the labels in list form\n",
        "train_class_list = []\n",
        "for label_file in train_labels_list:\n",
        "  label_file_open = open(label_file, \"r\")\n",
        "  file_contents = label_file_open.read()\n",
        "  object_class = file_contents.split('\\t', 1)[0]\n",
        "  if object_class == 'Coin':\n",
        "    train_class_list.append(0)\n",
        "  elif object_class == 'Cash':\n",
        "    train_class_list.append(1)\n",
        "train_class_nparray = np.asarray(train_class_list)\n",
        "\n",
        "validation_class_list = []\n",
        "for label_file in validation_labels_list:\n",
        "  label_file_open = open(label_file, \"r\")\n",
        "  file_contents = label_file_open.read()\n",
        "  object_class = file_contents.split('\\t', 1)[0]\n",
        "  if object_class == 'Coin':\n",
        "    validation_class_list.append(0)\n",
        "  elif object_class == 'Cash':\n",
        "    validation_class_list.append(1)\n",
        "validation_class_nparray = np.asarray(validation_class_list)\n",
        "\n",
        "test_class_list = []\n",
        "for label_file in test_labels_list:\n",
        "  label_file_open = open(label_file, \"r\")\n",
        "  file_contents = label_file_open.read()\n",
        "  object_class = file_contents.split('\\t', 1)[0]\n",
        "  if object_class == 'Coin':\n",
        "    test_class_list.append(0)\n",
        "  elif object_class == 'Cash':\n",
        "    test_class_list.append(1)\n",
        "test_class_nparray = np.asarray(test_class_list)\n",
        "\n",
        "##Build Model1\n",
        "model1 = keras.Sequential([\n",
        "        keras.layers.Conv2D(64, (6,6), activation='relu', input_shape=(80,80,3), data_format='channels_last'),\n",
        "        keras.layers.Conv2D(32, (6,6), activation='relu', data_format='channels_last'),\n",
        "        keras.layers.Flatten(), \n",
        "        keras.layers.Dense(2, activation='softmax')\n",
        "        ])  \n",
        "\n",
        "##Compile Model1\n",
        "model1.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "##Train Model1\n",
        "model1.fit(train_images_nparray, \n",
        "          train_class_nparray, \n",
        "          validation_data=(validation_images_nparray, validation_class_nparray),\n",
        "          epochs=100,\n",
        "          shuffle=True)\n",
        "\n",
        "##Build Model2\n",
        "model2 = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (6,6), activation='relu', input_shape=(80,80,3), data_format='channels_last'),\n",
        "        keras.layers.Conv2D(32, (6,6), activation='relu', data_format='channels_last'),\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "##Compile Model2\n",
        "model2.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "##Train Model2\n",
        "model2.fit(train_images_nparray, \n",
        "          train_class_nparray, \n",
        "          validation_data=(validation_images_nparray, validation_class_nparray),\n",
        "          epochs=100,\n",
        "          shuffle=True)\n",
        "\n",
        "##Make Predictions\n",
        "predictions1 = model1.predict(test_images_nparray)\n",
        "print(predictions1)\n",
        "predictions2 = model2.predict(test_images_nparray)\n",
        "print(predictions2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}